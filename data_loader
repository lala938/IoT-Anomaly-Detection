import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split

def load_and_preprocess(dataset_path, dataset_name='Bot-IoT'):
    """
    Load and preprocess IoT anomaly detection dataset
    Args:
        dataset_path: Path to dataset CSV file
        dataset_name: Dataset name ('Bot-IoT' or 'CIC-IDS2018')
    Returns:
        X_train, X_test, y_train, y_test: Train/test splits
    """
    print(f"Loading {dataset_name} dataset...")
    
    # Read data (optimized for large files)
    df = pd.read_csv(dataset_path, low_memory=False)
    
    # Dataset-specific preprocessing
    if dataset_name == 'Bot-IoT':
        # Remove unnecessary columns
        df.drop(columns=['saddr', 'sport', 'daddr', 'dport', 'seq', 'stddev', 'min', 'max'], 
               inplace=True, errors='ignore')
        
        # Binary target encoding
        df['attack'] = df['attack'].apply(lambda x: 1 if x > 0 else 0)
        y = df['attack'].values
        X = df.drop(columns=['attack']).values
        
    elif dataset_name == 'CIC-IDS2018':
        # Handle missing values
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df.dropna(inplace=True)
        
        # Label encoding
        label_encoder = LabelEncoder()
        y = label_encoder.fit_transform(df['Label'])
        X = df.drop(columns=['Label']).values
    
    # Feature standardization
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    # Train-test split (70:30 ratio)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"Dataset loaded! Samples: {X.shape[0]}, Features: {X.shape[1]}")
    print(f"Training set: {X_train.shape[0]} samples, Test set: {X_test.shape[0]} samples")
    print(f"Anomaly ratio: {np.mean(y)*100:.2f}%")
    
    return X_train, X_test, y_train, y_test
